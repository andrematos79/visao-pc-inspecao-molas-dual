config_molas.json

{
  "threshold_presente": 0.40,
  "normalize_lab_equalize": true,
  "roi": {
    "ESQ": { "x0": 8, "x1": 35, "y0": 10, "y1": 82 },
    "DIR": { "x0": 74, "x1": 100, "y0": 17, "y1": 83 }
  }
}


#########################################################################

app_camera_infer_dual_freeze.py

from pathlib import Path
import json
import time

import numpy as np
import cv2
import streamlit as st
import tensorflow as tf


# ==========================================================
# CONFIG / PATHS
# ==========================================================
BASE_DIR = Path(__file__).resolve().parent
MODEL_PATH = BASE_DIR / "modelo_molas.keras"
LABELS_PATH = BASE_DIR / "labels.json"

IMG_SIZE = (224, 224)  # igual ao treino
DEFAULT_THRESH_PRESENTE = 0.80  # com preprocess correto, tende a ficar alto

# ROIs default (em %)
DEFAULT_ROI = {
    "ESQ": {"x0": 8,  "x1": 35,  "y0": 10, "y1": 82},
    "DIR": {"x0": 74, "x1": 100, "y0": 17, "y1": 83},
}


# ==========================================================
# HELPERS
# ==========================================================
def load_labels(path: Path) -> list[str]:
    if not path.exists():
        raise FileNotFoundError(f"labels n√£o encontrado: {path}")
    data = json.loads(path.read_text(encoding="utf-8"))
    if not isinstance(data, list) or not all(isinstance(x, str) for x in data):
        raise ValueError("labels.json deve ser uma LISTA, ex: ['mola_ausente','mola_presente']")
    return data


@st.cache_resource(show_spinner=False)
def load_model_cached(path_str: str) -> tf.keras.Model:
    path = Path(path_str)
    if not path.exists():
        raise FileNotFoundError(f"modelo n√£o encontrado: {path}")
    return tf.keras.models.load_model(path, compile=False)


def clamp01(v: float) -> float:
    return max(0.0, min(1.0, v))


def crop_roi_percent(frame_bgr: np.ndarray, x0p, x1p, y0p, y1p) -> np.ndarray:
    h, w = frame_bgr.shape[:2]
    x0 = int(clamp01(x0p / 100.0) * w)
    x1 = int(clamp01(x1p / 100.0) * w)
    y0 = int(clamp01(y0p / 100.0) * h)
    y1 = int(clamp01(y1p / 100.0) * h)

    x0, x1 = sorted([x0, x1])
    y0, y1 = sorted([y0, y1])

    if x1 - x0 < 10 or y1 - y0 < 10:
        return frame_bgr.copy()

    return frame_bgr[y0:y1, x0:x1].copy()


def equalize_lab_bgr(img_bgr: np.ndarray) -> np.ndarray:
    """Equaliza apenas o canal L no espa√ßo LAB (melhora contraste sem destruir cor)."""
    lab = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    l2 = cv2.equalizeHist(l)
    lab2 = cv2.merge([l2, a, b])
    return cv2.cvtColor(lab2, cv2.COLOR_LAB2BGR)


def preprocess_bgr_for_model(frame_bgr: np.ndarray) -> np.ndarray:
    """
    IMPORTANTE:
    - Seu modelo (MobileNetV2) j√° tem preprocess_input dentro do grafo.
    - Ent√£o aqui a gente entrega RGB float32 em escala [0..255] (SEM /255).
    """
    img = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)
    img = cv2.resize(img, IMG_SIZE, interpolation=cv2.INTER_AREA)
    img = img.astype(np.float32)  # mant√©m 0..255
    return np.expand_dims(img, axis=0)


def predict_one(model: tf.keras.Model, labels: list[str], frame_bgr: np.ndarray):
    x = preprocess_bgr_for_model(frame_bgr)
    probs = model.predict(x, verbose=0)[0]
    idx = int(np.argmax(probs))
    cls = labels[idx]
    conf = float(probs[idx])
    return cls, conf, probs


def prob_of_class(labels: list[str], probs: np.ndarray, class_name: str) -> float:
    if class_name not in labels:
        return 0.0
    return float(probs[labels.index(class_name)])


def overlay_header(frame_bgr: np.ndarray, text: str) -> np.ndarray:
    out = frame_bgr.copy()
    h, w = out.shape[:2]
    bar_h = max(38, int(h * 0.10))
    cv2.rectangle(out, (0, 0), (w, bar_h), (0, 0, 0), -1)
    cv2.putText(out, text, (15, int(bar_h * 0.70)),
                cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 3, cv2.LINE_AA)
    return out


def read_one_frame(cap: cv2.VideoCapture):
    if cap is None or not cap.isOpened():
        return None
    ok, frame = cap.read()
    if not ok or frame is None:
        return None
    return frame


# ==========================================================
# STREAMLIT APP
# ==========================================================
st.set_page_config(page_title="Inspe√ß√£o de Molas ‚Äî DUAL (modo est√°vel)", layout="wide")
st.title("Inspe√ß√£o de Molas ‚Äî DUAL (modo est√°vel) ‚úÖ")
st.caption("Carregue o modelo, use **Ligar c√¢mera** (se quiser), e rode **Capturar + Inferir (DUAL)** ou **Inferir imagem (DUAL)**.")

# ---- Estado
if "model" not in st.session_state:
    st.session_state.model = None
if "labels" not in st.session_state:
    st.session_state.labels = None
if "camera_on" not in st.session_state:
    st.session_state.camera_on = False
if "last_frame" not in st.session_state:
    st.session_state.last_frame = None
if "frozen" not in st.session_state:
    st.session_state.frozen = False
if "frozen_frame" not in st.session_state:
    st.session_state.frozen_frame = None


# ==========================================================
# SIDEBAR
# ==========================================================
st.sidebar.header("C√¢mera")
cam_index = st.sidebar.number_input("√çndice da c√¢mera (0,1,2...)", min_value=0, max_value=10, value=0, step=1)
use_dshow = st.sidebar.checkbox("Usar DirectShow (Windows)", value=True)

st.sidebar.header("Modelo")
btn_load = st.sidebar.button("Carregar modelo", use_container_width=True)

st.sidebar.header("Execu√ß√£o")
th_presente = st.sidebar.slider(
    "Threshold m√≠nimo para MOLA PRESENTE",
    0.10, 0.99,
    float(DEFAULT_THRESH_PRESENTE),
    0.01
)

st.sidebar.header("ROI (%) ‚Äî padr√£o igual treino")
esq_x0 = st.sidebar.slider("ESQ x0 (%)", 0, 100, int(DEFAULT_ROI["ESQ"]["x0"]), 1)
esq_x1 = st.sidebar.slider("ESQ x1 (%)", 0, 100, int(DEFAULT_ROI["ESQ"]["x1"]), 1)
esq_y0 = st.sidebar.slider("ESQ y0 (%)", 0, 100, int(DEFAULT_ROI["ESQ"]["y0"]), 1)
esq_y1 = st.sidebar.slider("ESQ y1 (%)", 0, 100, int(DEFAULT_ROI["ESQ"]["y1"]), 1)

dir_x0 = st.sidebar.slider("DIR x0 (%)", 0, 100, int(DEFAULT_ROI["DIR"]["x0"]), 1)
dir_x1 = st.sidebar.slider("DIR x1 (%)", 0, 100, int(DEFAULT_ROI["DIR"]["x1"]), 1)
dir_y0 = st.sidebar.slider("DIR y0 (%)", 0, 100, int(DEFAULT_ROI["DIR"]["y0"]), 1)
dir_y1 = st.sidebar.slider("DIR y1 (%)", 0, 100, int(DEFAULT_ROI["DIR"]["y1"]), 1)

st.sidebar.divider()
normalize_roi = st.sidebar.checkbox("Normalizar ROI (LAB equalize)", value=True)
show_debug = st.sidebar.checkbox("Mostrar debug", value=False)

st.sidebar.divider()
col_cam_btns = st.sidebar.columns(2)
with col_cam_btns[0]:
    btn_cam_on = st.button("üì∑ Ligar c√¢mera", use_container_width=True)
with col_cam_btns[1]:
    btn_cam_off = st.button("‚õî Desligar", use_container_width=True)

btn_capture = st.sidebar.button("üì∏ Capturar + Inferir (DUAL)", type="primary", use_container_width=True)
btn_live = st.sidebar.button("‚ñ∂Ô∏è Voltar ao LIVE", use_container_width=True)

st.sidebar.divider()
st.sidebar.header("Imagem")
upload = st.sidebar.file_uploader("Enviar imagem (JPG/PNG)", type=["jpg", "jpeg", "png", "bmp", "webp"])
btn_infer_upload = st.sidebar.button("üñºÔ∏è Inferir imagem (DUAL)", use_container_width=True)

# ==========================================================
# TOP FILE STATUS
# ==========================================================
st.subheader("Arquivos")
st.write(f"modelo existe? ‚úÖ {MODEL_PATH.exists()}  ‚Üí  `{MODEL_PATH}`")
st.write(f"labels existe? ‚úÖ {LABELS_PATH.exists()}  ‚Üí  `{LABELS_PATH}`")


# ==========================================================
# LOAD MODEL
# ==========================================================
if btn_load:
    try:
        labels = load_labels(LABELS_PATH)
        model = load_model_cached(str(MODEL_PATH))
        st.session_state.labels = labels
        st.session_state.model = model
        st.success(f"Modelo carregado! Labels: {labels}")
    except Exception as e:
        st.session_state.model = None
        st.session_state.labels = None
        st.error(str(e))


# ==========================================================
# CAMERA CONTROL
# ==========================================================
if btn_cam_on:
    st.session_state.camera_on = True
    st.session_state.frozen = False
    st.session_state.frozen_frame = None

if btn_cam_off:
    st.session_state.camera_on = False

if btn_live:
    st.session_state.frozen = False
    st.session_state.frozen_frame = None

# ==========================================================
# READ CAMERA (stable: no infinite rerun)
# ==========================================================
cap = None
if st.session_state.camera_on:
    backend = cv2.CAP_DSHOW if use_dshow else cv2.CAP_ANY
    cap = cv2.VideoCapture(int(cam_index), backend)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)

    frame = read_one_frame(cap)
    if frame is not None:
        st.session_state.last_frame = frame

    if cap is not None:
        cap.release()


# ==========================================================
# CAPTURE FREEZE
# ==========================================================
if btn_capture:
    if st.session_state.last_frame is not None:
        st.session_state.frozen = True
        st.session_state.frozen_frame = st.session_state.last_frame.copy()
    else:
        st.warning("Sem frame. Ligue a c√¢mera ou use upload de imagem.")


# ==========================================================
# UPLOAD INFERENCE (freeze frame from upload)
# ==========================================================
if btn_infer_upload:
    if upload is None:
        st.warning("Envie uma imagem primeiro.")
    else:
        file_bytes = np.asarray(bytearray(upload.read()), dtype=np.uint8)
        img_bgr = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)
        if img_bgr is None:
            st.error("N√£o consegui ler a imagem enviada.")
        else:
            st.session_state.frozen = True
            st.session_state.frozen_frame = img_bgr
            st.session_state.last_frame = img_bgr


# ==========================================================
# RENDER
# ==========================================================
main_col, right_col = st.columns([3, 2], gap="large")

display_frame = st.session_state.frozen_frame if (st.session_state.frozen and st.session_state.frozen_frame is not None) else st.session_state.last_frame

with main_col:
    st.subheader("Preview")
    if display_frame is None:
        st.warning("Sem frame. Ligue a c√¢mera e aguarde aparecer imagem, ou use upload.")
    else:
        header = "LIVE ??? ajuste o enquadramento e clique em Capturar + Inferir"
        if st.session_state.frozen:
            header = "CAPTURADO ??? pronto para inferir"
        img_show = overlay_header(display_frame, header)
        st.image(cv2.cvtColor(img_show, cv2.COLOR_BGR2RGB), use_container_width=True)

with right_col:
    st.subheader("Resultado")

    if display_frame is None:
        st.info("Sem infer√™ncia ainda.")
    else:
        roi_esq = crop_roi_percent(display_frame, esq_x0, esq_x1, esq_y0, esq_y1)
        roi_dir = crop_roi_percent(display_frame, dir_x0, dir_x1, dir_y0, dir_y1)

        if normalize_roi:
            roi_esq = equalize_lab_bgr(roi_esq)
            roi_dir = equalize_lab_bgr(roi_dir)

        c1, c2 = st.columns(2)
        with c1:
            st.caption("ROI ESQ")
            st.image(cv2.cvtColor(roi_esq, cv2.COLOR_BGR2RGB), use_container_width=True)
        with c2:
            st.caption("ROI DIR")
            st.image(cv2.cvtColor(roi_dir, cv2.COLOR_BGR2RGB), use_container_width=True)

        if not st.session_state.frozen:
            st.info("Clique em **Capturar + Inferir (DUAL)** (ou use upload) para classificar.")
        else:
            if st.session_state.model is None or st.session_state.labels is None:
                st.warning("Modelo ainda n√£o carregado. Clique em **Carregar modelo**.")
            else:
                model = st.session_state.model
                labels = st.session_state.labels

                cls_e, conf_e, probs_e = predict_one(model, labels, roi_esq)
                cls_d, conf_d, probs_d = predict_one(model, labels, roi_dir)

                # Prob da classe "mola_presente"
                p_pres_e = prob_of_class(labels, probs_e, "mola_presente")
                p_pres_d = prob_of_class(labels, probs_d, "mola_presente")

                presente_e = (p_pres_e >= th_presente)
                presente_d = (p_pres_d >= th_presente)

                final_ok = presente_e and presente_d
                final_txt = "OK ‚úÖ" if final_ok else "NG ‚ùå"

                motivos = []
                if not presente_e:
                    motivos.append("ESQ sem mola")
                if not presente_d:
                    motivos.append("DIR sem mola")
                motivo_txt = " | ".join(motivos) if motivos else "Ambas molas presentes"

                st.markdown(f"### Resultado Final: **{final_txt}**")
                st.write(f"**ESQ:** p_mola_presente = {p_pres_e*100:.1f}% (Presente? {presente_e})")
                st.write(f"**DIR:** p_mola_presente = {p_pres_d*100:.1f}% (Presente? {presente_d})")
                st.caption(f"Motivo: {motivo_txt}")

                if show_debug:
                    st.divider()
                    st.caption("Debug probs (ESQ/DIR)")
                    st.write(dict(zip(labels, probs_e.tolist())))
                    st.write(dict(zip(labels, probs_d.tolist())))

# Observa√ß√£o: sem auto-refresh agressivo (mais est√°vel)



#############################################################################################################


split_dataset.py

from pathlib import Path
import random
import shutil

# ==========================
# CONFIG
# ==========================
SEED = 42
SPLIT = (0.80, 0.10, 0.10)  # train, val, test

BASE_DIR = Path(__file__).resolve().parent

RAW_DIR = BASE_DIR / "dataset_mola_roi_raw"          # <-- ajuste se seu nome for outro
OUT_DIR = BASE_DIR / "dataset_mola_roi_split"        # <-- opcional

CLASSES = ["mola_presente", "mola_ausente"]
IMG_EXTS = {".jpg", ".jpeg", ".png", ".bmp", ".webp", ".tif", ".tiff"}

random.seed(SEED)


def list_images(class_dir: Path):
    if not class_dir.exists():
        return []
    files = []
    for p in class_dir.rglob("*"):
        if p.is_file() and p.suffix.lower() in IMG_EXTS:
            files.append(p)
    return sorted(files)


def ensure_clean_out():
    # cria estrutura OUT_DIR/train|val|test/<classe>
    for split in ["train", "val", "test"]:
        for c in CLASSES:
            d = OUT_DIR / split / c
            d.mkdir(parents=True, exist_ok=True)


def copy_files(files, dst_dir: Path):
    dst_dir.mkdir(parents=True, exist_ok=True)
    for src in files:
        dst = dst_dir / src.name
        if dst.exists():
            dst = dst_dir / f"{src.stem}__dup{random.randint(1000,9999)}{src.suffix}"
        shutil.copy2(src, dst)


def main():
    print("BASE_DIR:", BASE_DIR)
    print("RAW_DIR:", RAW_DIR)
    print("OUT_DIR:", OUT_DIR)

    if abs(sum(SPLIT) - 1.0) > 1e-6:
        raise ValueError("SPLIT precisa somar 1.0 (ex.: 0.8,0.1,0.1)")

    ensure_clean_out()

    total_all = 0
    for c in CLASSES:
        class_dir = RAW_DIR / c
        imgs = list_images(class_dir)

        print(f"\nClasse '{c}': pasta = {class_dir}")
        print(f"  -> imagens encontradas: {len(imgs)}")

        total_all += len(imgs)

        if len(imgs) == 0:
            if class_dir.exists():
                any_files = [p.name for p in class_dir.iterdir() if p.is_file()]
                print("  Arquivos (n√£o-imagem ou extens√£o n√£o reconhecida):", any_files[:10])
            continue

        random.shuffle(imgs)

        n = len(imgs)
        n_train = int(n * SPLIT[0])
        n_val = int(n * SPLIT[1])
        n_test = n - n_train - n_val

        train_files = imgs[:n_train]
        val_files = imgs[n_train:n_train + n_val]
        test_files = imgs[n_train + n_val:]

        print(f"  -> split: train={len(train_files)} val={len(val_files)} test={len(test_files)}")

        copy_files(train_files, OUT_DIR / "train" / c)
        copy_files(val_files, OUT_DIR / "val" / c)
        copy_files(test_files, OUT_DIR / "test" / c)

    print("\n‚úÖ Dataset dividido com sucesso!")
    print("Total de imagens (todas classes):", total_all)


if __name__ == "__main__":
    main()


##############################################################################################################


train_tf_molas.py

# train_tf_molas.py
from pathlib import Path
import json
import os
import numpy as np
import tensorflow as tf

# =========================
# CONFIG
# =========================
BASE_DIR = Path(__file__).resolve().parent

# Dataset splitado (train/val/test)
DATASET_DIR = BASE_DIR / "dataset_mola_roi_split"  # <-- ajuste se o nome for outro
TRAIN_DIR = DATASET_DIR / "train"
VAL_DIR   = DATASET_DIR / "val"
TEST_DIR  = DATASET_DIR / "test"

# 2 classes (ordem fixa!)
CLASSES = ["mola_ausente", "mola_presente"]

IMG_SIZE = (224, 224)
BATCH_SIZE = 16
EPOCHS = 10
SEED = 42

MODEL_OUT  = BASE_DIR / "modelo_molas.keras"
LABELS_OUT = BASE_DIR / "labels.json"
CM_PNG_OUT = BASE_DIR / "confusion_matrix_test.png"

# =========================
# HELPERS
# =========================
IMG_EXTS = {".jpg", ".jpeg", ".png", ".bmp", ".webp"}

def count_images(root: Path, classes):
    counts = {}
    total = 0
    for c in classes:
        p = root / c
        n = 0
        if p.exists():
            n = sum(1 for f in p.rglob("*") if f.suffix.lower() in IMG_EXTS)
        counts[c] = n
        total += n
    return counts, total

def make_ds(dir_path: Path, shuffle: bool):
    ds = tf.keras.utils.image_dataset_from_directory(
        dir_path,
        labels="inferred",
        class_names=CLASSES,     # garante mapeamento correto
        color_mode="rgb",
        batch_size=BATCH_SIZE,
        image_size=IMG_SIZE,
        shuffle=shuffle,
        seed=SEED,
    )
    return ds

def build_model(num_classes: int):
    # Augmentation leve (robustez de linha)
    aug = tf.keras.Sequential([
        tf.keras.layers.RandomBrightness(factor=0.10),
        tf.keras.layers.RandomContrast(factor=0.10),
    ], name="augmentation")

    base = tf.keras.applications.MobileNetV2(
        input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3),
        include_top=False,
        weights="imagenet",
    )
    base.trainable = False

    inputs = tf.keras.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))
    x = aug(inputs)
    x = tf.keras.applications.mobilenet_v2.preprocess_input(x)
    x = base(x, training=False)
    x = tf.keras.layers.GlobalAveragePooling2D()(x)
    x = tf.keras.layers.Dropout(0.2)(x)
    outputs = tf.keras.layers.Dense(num_classes, activation="softmax")(x)
    model = tf.keras.Model(inputs, outputs)
    return model, base

def save_confusion_matrix_png(cm: np.ndarray, labels, out_path: Path):
    import matplotlib
    matplotlib.use("Agg")
    import matplotlib.pyplot as plt

    fig = plt.figure(figsize=(6, 5), dpi=150)
    ax = fig.add_subplot(111)
    ax.imshow(cm)
    ax.set_title("Confusion Matrix (TEST)")
    ax.set_xlabel("Predicted")
    ax.set_ylabel("True")
    ax.set_xticks(range(len(labels)))
    ax.set_xticklabels(labels, rotation=45, ha="right")
    ax.set_yticks(range(len(labels)))
    ax.set_yticklabels(labels)

    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            ax.text(j, i, str(cm[i, j]), ha="center", va="center")

    fig.tight_layout()
    fig.savefig(out_path)
    plt.close(fig)

# =========================
# MAIN
# =========================
def main():
    print("BASE_DIR:", BASE_DIR)
    print("DATASET_DIR:", DATASET_DIR)

    for name, p in [("TRAIN_DIR", TRAIN_DIR), ("VAL_DIR", VAL_DIR), ("TEST_DIR", TEST_DIR)]:
        if not p.exists():
            raise FileNotFoundError(f"Pasta n√£o existe: {p} (esperado {name})")

    tr_counts, tr_total = count_images(TRAIN_DIR, CLASSES)
    va_counts, va_total = count_images(VAL_DIR, CLASSES)
    te_counts, te_total = count_images(TEST_DIR, CLASSES)

    print("\n== CONTAGEM ==")
    print("train:", tr_counts, "total:", tr_total)
    print("val  :", va_counts, "total:", va_total)
    print("test :", te_counts, "total:", te_total)

    if tr_total == 0 or va_total == 0 or te_total == 0:
        raise RuntimeError("Tem split com zero imagens. Confere as pastas train/val/test e as classes.")

    train_ds = make_ds(TRAIN_DIR, shuffle=True)
    val_ds   = make_ds(VAL_DIR, shuffle=False)
    test_ds  = make_ds(TEST_DIR, shuffle=False)

    AUTOTUNE = tf.data.AUTOTUNE
    train_ds = train_ds.cache().shuffle(1000).prefetch(AUTOTUNE)
    val_ds   = val_ds.cache().prefetch(AUTOTUNE)
    test_ds  = test_ds.cache().prefetch(AUTOTUNE)

    model, base = build_model(num_classes=len(CLASSES))
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),
        loss="sparse_categorical_crossentropy",
        metrics=["accuracy"],
    )

    # class_weight = total / (num_classes * count_da_classe)
    class_weight = {}
    for i, c in enumerate(CLASSES):
        n = tr_counts[c]
        class_weight[i] = (tr_total / (len(CLASSES) * max(1, n)))
    print("\nclass_weight:", class_weight)

    callbacks = [
        tf.keras.callbacks.EarlyStopping(monitor="val_accuracy", patience=3, restore_best_weights=True),
        tf.keras.callbacks.ReduceLROnPlateau(monitor="val_loss", factor=0.5, patience=2, min_lr=1e-6),
    ]

    print("\n== TREINO (BASE CONGELADA) ==")
    model.fit(
        train_ds,
        validation_data=val_ds,
        epochs=EPOCHS,
        callbacks=callbacks,
        class_weight=class_weight,
        verbose=1
    )

    # Fine-tuning leve (opcional, mas recomendo)
    print("\n== FINE-TUNING (√∫ltimas camadas) ==")
    base.trainable = True
    for layer in base.layers[:-30]:
        layer.trainable = False

    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),
        loss="sparse_categorical_crossentropy",
        metrics=["accuracy"],
    )
    model.fit(
        train_ds,
        validation_data=val_ds,
        epochs=3,
        verbose=1
    )

    model.save(MODEL_OUT)
    with open(LABELS_OUT, "w", encoding="utf-8") as f:
        json.dump(CLASSES, f, ensure_ascii=False, indent=2)

    print(f"\n‚úÖ Modelo salvo em: {MODEL_OUT}")
    print(f"‚úÖ Labels salvos em: {LABELS_OUT}")

    print("\n== AVALIANDO NO TEST ==")
    test_loss, test_acc = model.evaluate(test_ds, verbose=1)
    print(f"Test loss: {test_loss:.4f} | Test acc: {test_acc:.4f}")

    y_true, y_pred = [], []
    for batch_x, batch_y in test_ds:
        probs = model.predict(batch_x, verbose=0)
        preds = np.argmax(probs, axis=1)
        y_true.extend(batch_y.numpy().tolist())
        y_pred.extend(preds.tolist())

    cm = tf.math.confusion_matrix(y_true, y_pred, num_classes=len(CLASSES)).numpy()
    print("\nConfusion matrix (TEST):")
    print(cm)

    save_confusion_matrix_png(cm, CLASSES, CM_PNG_OUT)
    print(f"\n‚úÖ Confusion matrix PNG salva em: {CM_PNG_OUT}")

if __name__ == "__main__":
    os.environ["TF_CPP_MIN_LOG_LEVEL"] = "1"
    main()

#############################################################################################################


gerar_datast_ro_dual.py

# gerar_dataset_roi_dual.py  (VERS√ÉO CORRIGIDA ‚Äî BIN√ÅRIO POR ROI)
# Gera ROIs ESQ/DIR a partir de imagens inteiras e salva em:
# OUT_DIR/mola_presente e OUT_DIR/mola_ausente

from pathlib import Path
import cv2

# =========================
# CONFIG
# =========================
BASE_DIR = Path(__file__).resolve().parent

# Pasta com as imagens inteiras separadas por classe de origem
# Exemplo de estrutura em IN_DIR:
# dataset_raw/
#   ok/
#   ng_ausente_esq/
#   ng_ausente_dir/
#   ng_ausente_ambas/
IN_DIR  = BASE_DIR / "dataset_raw"

# Sa√≠da: dataset "raw" j√° por ROI e bin√°rio (para depois rodar split_dataset.py)
OUT_DIR = BASE_DIR / "dataset_mola_roi_raw"

# Ajuste estes ROIs (em %) com os valores que voc√™ est√° usando no app
# (os mesmos sliders: x0,x1,y0,y1 em %)
ROI = {
    "ESQ": {"x0": 8,  "x1": 35,  "y0": 10, "y1": 82},   # EXEMPLO
    "DIR": {"x0": 74, "x1": 100, "y0": 17, "y1": 83},   # EXEMPLO
}

# Extens√µes aceitas
EXTS = {".jpg", ".jpeg", ".png", ".bmp", ".webp"}

# Se voc√™ quiser for√ßar o tamanho da ROI (igual do treino e infer√™ncia)
ENABLE_RESIZE = True
IMG_SIZE = (224, 224)  # (W,H) - OpenCV usa (W,H)

# Se True, ignora classes desconhecidas e segue (com WARN).
# Se False, o script para no primeiro erro (mais seguro).
SKIP_UNKNOWN_CLASSES = False


# =========================
# HELPERS
# =========================
def list_images(folder: Path):
    if not folder.exists():
        return []
    return [p for p in folder.rglob("*") if p.suffix.lower() in EXTS and p.is_file()]

def crop_roi(img, roi_pct):
    h, w = img.shape[:2]
    x0 = int(w * roi_pct["x0"] / 100.0)
    x1 = int(w * roi_pct["x1"] / 100.0)
    y0 = int(h * roi_pct["y0"] / 100.0)
    y1 = int(h * roi_pct["y1"] / 100.0)

    # clamp
    x0 = max(0, min(w - 1, x0))
    x1 = max(1, min(w, x1))
    y0 = max(0, min(h - 1, y0))
    y1 = max(1, min(h, y1))

    if x1 <= x0 or y1 <= y0:
        raise ValueError(f"ROI inv√°lido: {roi_pct} -> px {(x0, x1, y0, y1)}")

    return img[y0:y1, x0:x1].copy()

def maybe_resize(img):
    if not ENABLE_RESIZE:
        return img
    return cv2.resize(img, IMG_SIZE, interpolation=cv2.INTER_AREA)

def save_img(path: Path, img):
    path.parent.mkdir(parents=True, exist_ok=True)
    ok = cv2.imwrite(str(path), img)
    if not ok:
        raise RuntimeError(f"Falha ao salvar: {path}")

def safe_name(s: str):
    # evita espa√ßos/acentos simples (opcional)
    return s.replace(" ", "_")


# =========================
# MAPEAMENTO DE R√ìTULOS (BIN√ÅRIO)
# =========================
# Entrada (foto inteira) -> r√≥tulo por ROI (ESQ/DIR) em 2 classes:
# mola_presente / mola_ausente
def labels_for_rois(src_class: str):
    """
    src_class √© o nome da pasta de origem dentro do dataset_raw.
    Retorna dict: {"ESQ": label, "DIR": label}
    """
    s = src_class.lower().strip()

    # OK: as duas molas presentes
    if s == "ok":
        return {"ESQ": "mola_presente", "DIR": "mola_presente"}

    # Aus√™ncia por lado
    if s in {"ng_ausente_esq", "ausente_esq"}:
        return {"ESQ": "mola_ausente", "DIR": "mola_presente"}
    if s in {"ng_ausente_dir", "ausente_dir"}:
        return {"ESQ": "mola_presente", "DIR": "mola_ausente"}
    if s in {"ng_ausente_ambas", "ng_ausente_duas", "ausente_ambas", "ausente_duas"}:
        return {"ESQ": "mola_ausente", "DIR": "mola_ausente"}

    # Desalinhamento n√£o entra nesse modelo bin√°rio (evita contaminar dataset)
    if "desalinh" in s:
        raise ValueError(
            f"Classe '{src_class}' √© desalinhamento. "
            "Neste modelo bin√°rio (presente/ausente) isso deve ficar fora do dataset."
        )

    # Classe gen√©rica sem lado definido: erro para n√£o treinar errado
    if s in {"ng_ausente", "ausente"}:
        raise ValueError(
            "Pasta 'ng_ausente' sem lado definido. "
            "Crie subpastas: ng_ausente_esq / ng_ausente_dir / ng_ausente_ambas."
        )

    raise ValueError(f"Classe desconhecida no dataset_raw: '{src_class}'")


# =========================
# MAIN
# =========================
def main():
    print("BASE_DIR:", BASE_DIR)
    print("IN_DIR :", IN_DIR)
    print("OUT_DIR:", OUT_DIR)
    print("ROI ESQ:", ROI["ESQ"])
    print("ROI DIR:", ROI["DIR"])
    print("ENABLE_RESIZE:", ENABLE_RESIZE, "| IMG_SIZE:", IMG_SIZE)

    if not IN_DIR.exists():
        raise FileNotFoundError(f"N√£o achei {IN_DIR}")

    OUT_DIR.mkdir(parents=True, exist_ok=True)

    total_in = 0
    total_out = 0
    total_warn_roi = 0
    total_warn_read = 0
    total_skip_class = 0

    # percorre classes de origem
    class_dirs = [p for p in IN_DIR.iterdir() if p.is_dir()]
    if not class_dirs:
        raise RuntimeError(f"Nenhuma pasta de classe encontrada em {IN_DIR}")

    for class_dir in sorted(class_dirs):
        src_class = class_dir.name
        imgs = list_images(class_dir)
        print(f"\nClasse origem: {src_class} -> {len(imgs)} imagens")

        if not imgs:
            continue

        try:
            roi_labels = labels_for_rois(src_class)
        except Exception as e:
            msg = f"[WARN] Classe '{src_class}' ignorada: {e}"
            if SKIP_UNKNOWN_CLASSES:
                print(msg)
                total_skip_class += len(imgs)
                continue
            raise

        for img_path in imgs:
            total_in += 1
            img = cv2.imread(str(img_path))
            if img is None:
                total_warn_read += 1
                print("  [WARN] n√£o consegui ler:", img_path)
                continue

            try:
                crop_esq = maybe_resize(crop_roi(img, ROI["ESQ"]))
                crop_dir = maybe_resize(crop_roi(img, ROI["DIR"]))
            except Exception as e:
                total_warn_roi += 1
                print("  [WARN] ROI falhou em:", img_path.name, "|", e)
                continue

            stem = safe_name(img_path.stem)

            # salva com labels corretos por ROI (bin√°rio)
            out_esq = OUT_DIR / roi_labels["ESQ"] / f"{stem}__ESQ.jpg"
            out_dir = OUT_DIR / roi_labels["DIR"] / f"{stem}__DIR.jpg"

            save_img(out_esq, crop_esq)
            save_img(out_dir, crop_dir)

            total_out += 2

    print("\n‚úÖ Conclu√≠do!")
    print("Total imagens origem        :", total_in)
    print("Total ROIs geradas (ESQ+DIR):", total_out)
    print("WARN leitura (imread)       :", total_warn_read)
    print("WARN ROI inv√°lida           :", total_warn_roi)
    print("Imagens puladas por classe  :", total_skip_class)
    print("\nPr√≥ximo passo:")
    print("1) Rode split_dataset.py apontando para OUT_DIR (dataset_mola_roi_raw)")
    print("2) Treine com train_tf_molas.py apontando para o dataset splitado.")
    print("3) Use o app com threshold para MOLA PRESENTE (por ROI) + AND final.")

if __name__ == "__main__":
    main()


#########################################################################################################


labels.json

[
  "mola_ausente",
  "mola_presente"
]
